{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8f2dd3",
   "metadata": {},
   "source": [
    "#### 2023.12.28 第二版模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84455b24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/org_data\\2018_Namelist&OM Report_procurement.xlsx\n",
      "data/org_data\\2019_Namelist&OM Report_procurement.xlsx\n",
      "data/org_data\\2020_Namelist&OM Report_procurement.xlsx\n",
      "data/org_data\\2021_Namelist&OM Report_procurement.xlsx\n",
      "data/org_data\\2022_Namelist&OM Report_procurement.xlsx\n",
      "data\\Turnover Report_Procurement_201812_Final.xlsx\n",
      "data\\Turnover Report_Procurement_201912_Final.xlsx\n",
      "data\\Turnover Report_Procurement_202012-final-exclude DGO.xlsx\n",
      "data\\Turnover Report_Procurement_202112.xlsx\n",
      "data\\Turnover Report_Procurement_202212.xlsx\n",
      "data\\Turnover Report_Procurement_202310 APAC.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "import json\n",
    "from tools import *\n",
    "from required_data_src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575c9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 薪资数据ID是有重复的，有人有多次变动\n",
    "# duplicates = cr_src.groupby('ID')['Gender'].count()[cr_src.groupby('ID')['Gender'].count() > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32149f98",
   "metadata": {},
   "source": [
    "### Data preprocess\n",
    "#### 离职数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd50347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turnover_data = get_turnover_data(runtime=2)\n",
    "turnover_data['used_region_flag'] = turnover_data.apply(lambda x: define_used_region(x), axis=1)\n",
    "turnover_data = turnover_data.query('(used_region_flag > 0) & (LeaveType == \"Termination-Voluntary\")')\n",
    "turnover_data = turnover_data.query('ID != \"52710485-744498\"')     # onboardDate数据错误\n",
    "\n",
    "turnover_data['OnboardDate'] = pd.to_datetime(turnover_data['OnboardDate'].astype(str))\n",
    "turnover_data['LastWorkingdate'] = pd.to_datetime(turnover_data['LastWorkingdate'])\n",
    "turnover_data['duration'] = (turnover_data['LastWorkingdate'] - turnover_data['OnboardDate']).dt.days   # \n",
    "turnover_data = turnover_data.query(\"~((PAID == 7109) & (Age == 35))\")   # 有一个ID在离职表里是重复的，没有真的离职，从7109变成了CN21，而且还升职了\n",
    "remove_id = movement_src.query(\"ReasonofChange == 'Repatriate-Return to Home'\")['ID'].tolist()\n",
    "turnover_data = turnover_data[~turnover_data['ID'].isin(remove_id)]     #这个情况也不是主动离职\n",
    "turnover_data['Band_V'] = turnover_data['Band_V'].map(lambda x: re.sub(r'-A|-B','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9647d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "turnover_data['current_band'] = turnover_data['Band_V'].replace(roam_to_num_dict)      # 当前职级\n",
    "# turnover_data['current_year'] = '2023-10-31'     # 截止到2023.10.31的时候已经不是fte了\n",
    "turnover_data['current_year'] = turnover_data['LastWorkingdate'] - datetime.timedelta(days=31*6)\n",
    "turnover_data['is_fte'] = 0                      # FTE数据标签（负样本）\n",
    "turnover_data['on_duty_days'] = (turnover_data['current_year'] - turnover_data['OnboardDate']).dt.days    # 截止到半年前已经就职了多少天\n",
    "turnover_data['current_year'] = turnover_data['current_year'].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911e7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fte_used_columns = ['ID', 'Age', 'Gender', 'PAID', 'MacroEntity', 'positionName', 'OnboardDate', 'duration', \n",
    "                    'current_year', 'is_fte', 'current_band', 'on_duty_days']\n",
    "turnover_used_columns = fte_used_columns + ['LastWorkingdate']\n",
    "turnover_data = turnover_data[turnover_used_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648a5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_turnover_data = get_one_fte_snapshot(turnover_data)     # 获取movement的标签\n",
    "for i, year in enumerate([2022, 2021, 2020, 2019, 2018]):\n",
    "    turnover = turnover_data.copy()\n",
    "    turnover['current_year'] = f'{year}-12-31'\n",
    "    # LastWorkingdate 要大于 current + 6months\n",
    "    current_lag_6_date = datetime.datetime(*time.strptime(f'{year}-12-31', '%Y-%m-%d')[:6]) + datetime.timedelta(days=31*6)\n",
    "    current_lag_6_date_str = current_lag_6_date.strftime('%Y-%m-%d')\n",
    "    turnover.query(\"(OnboardDate <= current_year) & (LastWorkingdate > @current_lag_6_date_str)\")\n",
    "    turnover['duration'] = (turnover['LastWorkingdate'] - turnover['OnboardDate']).dt.days\n",
    "    turnover['on_duty_days'] = (pd.to_datetime(turnover['current_year']) - turnover['OnboardDate']).dt.days\n",
    "    turnover['Age'] = turnover['Age'] - i - 1\n",
    "    turnover['is_fte'] = 1\n",
    "    turnover = get_one_fte_snapshot(turnover)\n",
    "    final_turnover_data = pd.concat([final_turnover_data, turnover])\n",
    "final_turnover_data['src_file'] = 'turnover'     # 标记这部分数据来自于turnover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05949a6",
   "metadata": {},
   "source": [
    "#### 在职员工数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3a920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 对于预测数据，是要把on_duty_days的计算时间改成10.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f0fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fte = pd.read_excel('data/Turnover Report_Procurement_202310 APAC.xlsx', sheet_name='FTE') # 截止到2023年10月底的在职员工数据\n",
    "fte['ID'] = fte['ID'].astype(str).str.split('.').apply(\n",
    "            lambda x: \"-\".join([str(list(x)[0]), str(list(x)[1])[:6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7690de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "used_columns = item_def['FTE'].dropna().tolist()\n",
    "fte = fte[used_columns]\n",
    "fte.rename(columns={'LegalEntity': 'PAID', 'PositionName_EN':'positionName', \n",
    "                    'OnboardDate_Group': 'OnboardDate', 'PersBand':'Band_V',\n",
    "                    'AGE':'Age', 'EmployeeID':'ID'}, inplace=True)\n",
    "fte['used_region_flag'] = fte.apply(lambda x: define_used_region(x), axis=1)\n",
    "fte = fte.query('used_region_flag > 0')\n",
    "fte['OnboardDate'] = pd.to_datetime(fte['OnboardDate'])\n",
    "fte['duration'] = (pd.to_datetime('2023-10-31') - fte['OnboardDate']).dt.days       # 半年后2023-10-31还在，按照半年前4月底做feature\n",
    "fte['on_duty_days'] = (pd.to_datetime('2023-04-30') - fte['OnboardDate']).dt.days\n",
    "# fte数据要每年做出来一波还在职的作为数据集\n",
    "fte['current_year'] = '2023-04-30'\n",
    "fte['is_fte'] = 1                      # FTE数据标签\n",
    "fte['current_band'] = fte['Band_V'].replace(roam_to_num_dict)      # 当前职级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ddf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fte_used_columns = ['ID', 'Age', 'Gender', 'PAID', 'MacroEntity', 'positionName', 'OnboardDate', 'duration', \n",
    "                    'current_year', 'is_fte', 'current_band', 'on_duty_days']\n",
    "fte = fte[fte_used_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e193a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fte = get_one_fte_snapshot(fte)\n",
    "for i, year in enumerate([2022, 2021, 2020, 2019]):\n",
    "    fte2022 = fte.copy()\n",
    "    fte2022['current_year'] = f'{year}-12-31'\n",
    "    fte2022.query(\"OnboardDate <= current_year\")\n",
    "    fte2022['on_duty_days'] = (pd.to_datetime(fte2022['current_year']) - fte['OnboardDate']).dt.days\n",
    "    fte2022['duration'] = (pd.to_datetime('2023-10-31') - fte['OnboardDate']).dt.days    \n",
    "    fte2022['Age'] = fte2022['Age'] - i - 1\n",
    "    fte2022 = get_one_fte_snapshot(fte2022)\n",
    "    final_fte = pd.concat([final_fte, fte2022])\n",
    "final_fte['src_file'] = 'fte'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f160cc",
   "metadata": {},
   "source": [
    "#### 合并离职员工和在职员工的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1e6551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28079083\\OneDrive - Anheuser-Busch InBev\\Desktop\\2023项目\\9.turnover\\tools.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_org_data.drop(set(org_data_use_columns) - set({'ID'}), axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_combined = pd.concat([final_fte, final_turnover_data])\n",
    "data_combined.drop('LastWorkingdate', axis=1, inplace=True)    # 正样本955， 负样本97\n",
    "train_data = add_more_features(data_combined)\n",
    "train_data.to_excel('step_data/train_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e28d23",
   "metadata": {},
   "source": [
    "#### OPR数据 2023.12.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd75a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opr = pd.read_excel('data/2019-2023 OPR.xlsx')\n",
    "opr.columns = ['ID', 'Country', 2023, 2022, 2021, 2020, 2019]\n",
    "opr = opr.melt(id_vars=['ID'], value_vars=[2023, 2022, 2021, 2020, 2019], var_name='year', value_name='opr')\n",
    "opr['opr'] = np.where(opr['opr'].isin(['3A', '4A', '1A']), 'E', \n",
    "                      np.where(opr['opr'].isin(['3B', '4B']), 'M', \n",
    "                               np.where(opr['opr'].isin(['2']), 'N', opr['opr'])))\n",
    "opr['ID'] = opr['ID'].astype(str).str.split('.').apply(lambda x: \"-\".join([str(list(x)[0]), str(list(x)[1])[:6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96c37967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, opr, on=['ID', 'year'], how='left')\n",
    "train_data.to_excel('step_data/train_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263f092",
   "metadata": {},
   "source": [
    "#### 在职员工的预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21c2c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_fte = fte.copy()\n",
    "forecast_fte['current_year'] = '2023-10-31'\n",
    "forecast_fte['on_duty_days'] = (pd.to_datetime('2023-10-31') - forecast_fte['OnboardDate']).dt.days\n",
    "forecast_fte = get_one_fte_snapshot(forecast_fte)\n",
    "forecast_fte = add_more_features_forecast(forecast_fte)\n",
    "forecast_fte.to_excel('model_data/forecast_fte.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c29bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_fte = pd.read_excel('model_data/forecast_fte.xlsx')\n",
    "forecast_fte = pd.merge(forecast_fte, opr, on=['ID', 'year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d020fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_data, forecast_fte]).drop_duplicates(subset=['ID', 'year']).to_excel(\"data/check/missing_important_features_1222_train_and_forecast.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e02e70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[train_data['Job Family'].isnull()].drop_duplicates(subset=['ID']).to_excel('data/check/org_data_check.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87618cbd",
   "metadata": {},
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "003920ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used_features = pd.read_excel('模型标签.xlsx')['column'].tolist()\n",
    "categorical_features = ['Gender',  'end_of_date_position','end_of_date_MacroEntity','end_of_date_paid',\n",
    "                        'Organizational Unit','Line Manager ID', 'Job Family', '员工子组(OM)', '工作地 ID(OM)','Functional Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ab2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modeling_train_dataset(train_data, save_train=False):\n",
    "#     train_data = train_data[(train_data['recent_cr'].notnull())]\n",
    "    print(\"Initial turnover records ratio: {:.2%}\".format(train_data['is_fte'].value_counts()[0] / train_data['is_fte'].value_counts().sum()))   \n",
    "    train_fte_trunc = train_data.query('is_fte == 1').sample(n=400, random_state=24)            # 让train data的离职人占比20% \n",
    "    train_data_sub = pd.concat([train_fte_trunc, train_data.query('is_fte == 0')])\n",
    "    train_data_sub = train_data_sub.reset_index(drop=True)\n",
    "    train_data_sub = train_data_sub[model_used_features]\n",
    "    train_data_sub['y'] = 1 - train_data_sub['is_fte']    # y是半年后是否离职，还有一种是y=duration\n",
    "    if save_train:\n",
    "        train_data_sub.to_excel(\"model_data/train.xlsx\")\n",
    "    for col in categorical_features:\n",
    "        train_data_sub[col] = train_data_sub[col].astype(str)\n",
    "        train_data_sub[col] = train_data_sub[col].fillna('NA')\n",
    "    return train_data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75ffbcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial turnover records ratio: 8.25%\n",
      "train turnover ratio: 17.27%\n",
      "test turnover ratio: 18.56%\n"
     ]
    }
   ],
   "source": [
    "train_data_sub = get_modeling_train_dataset(train_data, save_train=False)\n",
    "X = train_data_sub.drop(['ID', 'duration', 'is_fte', 'y'], axis=1)\n",
    "y = train_data_sub['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=65)\n",
    "print(\"train turnover ratio: {:.2%}\".format(y_train.value_counts()[1] / y_train.value_counts().sum()))\n",
    "print(\"test turnover ratio: {:.2%}\".format(y_test.value_counts()[1] / y_test.value_counts().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "723fa99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465541490857947"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(**params)\n",
    "model.fit(X_train, y_train,eval_set=[(X_train, y_train),(X_test,y_test)],cat_features=categorical_features)\n",
    "test_pred = [pred[1] for pred in  model.predict_proba(X_test)]\n",
    "test_auc= roc_auc_score(list(y_test), test_pred)\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97392b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.052786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.884800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   0       tpr       fpr\n",
       "1  17   1  0.944444  0.052786\n",
       "0   9  70  0.113924  0.884800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "confusion_mat = confusion_matrix(y_test.tolist(), [int(x > threshold) for x in test_pred])\n",
    "confusionMatrix = pd.DataFrame(confusion_mat, columns=[0, 1], index=[0, 1]). \\\n",
    "    sort_index(axis=0, ascending=False).sort_index(axis=1, ascending=False)\n",
    "confusionMatrix[\"tpr\"] = confusionMatrix[1] / confusionMatrix.sum(axis=1)\n",
    "confusionMatrix[\"fpr\"] = confusionMatrix[0] / confusionMatrix.sum(axis=1)\n",
    "confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8ad710f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'loss_function': 'Logloss', # 损失函数，取值RMSE, Logloss, MAE, CrossEntropy, Quantile, LogLinQuantile, Multiclass, MultiClassOneVsAll, MAPE, Poisson。默认Logloss。\n",
    "    'custom_loss': 'AUC', # 训练过程中计算显示的损失函数，取值Logloss、CrossEntropy、Precision、Recall、F、F1、BalancedAccuracy、AUC等等\n",
    "    'eval_metric': 'AUC', # 用于过度拟合检测和最佳模型选择的指标，取值范围同custom_loss\n",
    "    'iterations': 40, # 最大迭代次数，默认500. 别名：num_boost_round, n_estimators, num_trees\n",
    "    'learning_rate': 0.3, # 学习速率,默认0.03 别名：eta\n",
    "    'random_seed': 23, # 训练的随机种子，别名：random_state\n",
    "#     'l2_leaf_reg': 5, # l2正则项，别名：reg_lambda\n",
    "    'bootstrap_type': 'Bernoulli', # 确定抽样时的样本权重，取值Bayesian、Bernoulli(伯努利实验)、MVS(仅支持cpu)、Poisson(仅支持gpu)、No（取值为No时，每棵树为简单随机抽样）;默认值GPU下为Bayesian、CPU下为MVS\n",
    "#     'bagging_temperature': 0,  # bootstrap_type=Bayesian时使用,取值为1时采样权重服从指数分布；取值为0时所有采样权重均等于1。取值范围[0，inf)，值越大、bagging就越激进\n",
    "#     'subsample': 0.6, # 样本采样比率（行采样）\n",
    "    'sampling_frequency': 'PerTreeLevel', # 采样频率，取值PerTree（在构建每棵新树之前采样）、PerTreeLevel（默认值，在子树的每次分裂之前采样）；仅支持CPU\n",
    "    'use_best_model': True, # 让模型使用效果最优的子树棵树/迭代次数，使用验证集的最优效果对应的迭代次数（eval_metric：评估指标，eval_set：验证集数据），布尔类型可取值0，1（取1时要求设置验证集数据）\n",
    "#     'best_model_min_trees': 50, # 最少子树棵树,和use_best_model一起使用\n",
    "    'depth': 4, # 树深，默认值6\n",
    "    'grow_policy': 'SymmetricTree', # 子树生长策略，取值SymmetricTree（默认值，对称树）、Depthwise（整层生长，同xgb）、Lossguide（叶子结点生长，同lgb）\n",
    "    'min_data_in_leaf': 6, # 叶子结点最小样本量\n",
    "#     'max_leaves': 12, # 最大叶子结点数量\n",
    "#     'one_hot_max_size': 4, # 对唯一值数量<one_hot_max_size的类别型特征使用one-hot编码\n",
    "#     'rsm': 0.6, # 列采样比率，别名colsample_bylevel 取值（0，1],默认值1\n",
    "    'nan_mode': 'Min', # 缺失值处理方法，取值Forbidden（不支持缺失值，输入包含缺失时会报错）、Min（处理为该列的最小值，比原最小值更小）、Max（同理）\n",
    "    'input_borders': None, # 特征数据边界（最大最小边界）、会影响缺失值的处理（nan_mode取值Min、Max时），默认值None、在训练时特征取值的最大最小值即为特征值边界\n",
    "    'boosting_type': 'Ordered', # 提升类型，取值Ordered（catboost特有的排序提升，在小数据集上效果可能更好，但是运行速度较慢）、Plain（经典提升）\n",
    "#     'max_ctr_complexity': 2, # 分类特征交叉的最高阶数，默认值4\n",
    "    'logging_level':'Silent', # 模型训练过程的信息输出等级，取值Silent（不输出信息）、Verbose（默认值，输出评估指标、已训练时间、剩余时间等）、Info（输出额外信息、树的棵树）、Debug（debug信息）\n",
    "    'metric_period': 1, # 计算目标值、评估指标的频率，默认值1、即每次迭代都输出目标值、评估指标\n",
    "#     'early_stopping_rounds': 20,\n",
    "#     'border_count': 254, # 数值型特征的分箱数，别名max_bin，取值范围[1,65535]、默认值254（CPU下), # 设置提前停止训练，在得到最佳的评估结果后、再迭代n（参数值为n）次停止训练，默认值不启用\n",
    "#     'feature_border_type': 'GreedyLogSum', # 数值型特征的分箱方法，取值Median、Uniform、UniformAndQuantiles、MaxLogSum、MinEntropy、GreedyLogSum（默认值）\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1dbdfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model result\n",
    "result_save_file = pd.ExcelWriter(\"model_data/model_result.xlsx\")\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns, name=\"feature_importance\")\n",
    "feature_importance.sort_values(ascending=False)\n",
    "feature_importance.to_excel(result_save_file, sheet_name='feature_importance')\n",
    "\n",
    "threshold = 0.3\n",
    "confusion_mat = confusion_matrix(y_test.tolist(), [int(x > threshold) for x in test_pred])\n",
    "confusionMatrix = pd.DataFrame(confusion_mat, columns=[0, 1], index=[0, 1]). \\\n",
    "    sort_index(axis=0, ascending=False).sort_index(axis=1, ascending=False)\n",
    "confusionMatrix[\"tpr\"] = confusionMatrix[1]/confusionMatrix.sum(axis=1)\n",
    "confusionMatrix[\"fpr\"] = confusionMatrix[0]/confusionMatrix.sum(axis=1)\n",
    "confusionMatrix.to_excel(result_save_file, sheet_name='confusion_matrix')\n",
    "result_save_file.close()\n",
    "\n",
    "with open(\"model_data/catboost_model.pk\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(\"model_data/catboost_model_params.txt\", 'w') as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fcafd0",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c77b654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28079083\\AppData\\Local\\Temp\\ipykernel_20536\\155970571.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast_data[col] = forecast_data[col].astype(str)\n",
      "C:\\Users\\28079083\\AppData\\Local\\Temp\\ipykernel_20536\\155970571.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast_data[col] = forecast_data[col].fillna('NA')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    95\n",
       "1     9\n",
       "Name: turnover_tag, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_data = forecast_fte[X_train.columns]\n",
    "for col in categorical_features:\n",
    "    forecast_data[col] = forecast_data[col].astype(str)\n",
    "    forecast_data[col] = forecast_data[col].fillna('NA')\n",
    "    \n",
    "predict_proba = [pred[1] for pred in  model.predict_proba(forecast_data)]\n",
    "forecast_result = pd.concat([forecast_fte, pd.Series(predict_proba, name='predict_p', index=forecast_fte.index)], axis=1)\n",
    "forecast_result['turnover_tag'] = forecast_result['predict_p'].apply(lambda x: 1 if x > threshold else 0)\n",
    "forecast_result['turnover_tag'].value_counts()\n",
    "forecast_result.to_excel('model_data/forecast_result2023.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34f235e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    101\n",
       "1      3\n",
       "Name: turnover_tag, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_result['turnover_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cf5e561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.33\n",
    "confusion_mat = confusion_matrix(y_test.tolist(), [int(x > threshold) for x in test_pred])\n",
    "confusionMatrix = pd.DataFrame(confusion_mat, columns=[0, 1], index=[0, 1]). \\\n",
    "    sort_index(axis=0, ascending=False).sort_index(axis=1, ascending=False)\n",
    "confusionMatrix[\"tpr\"] = confusionMatrix[1] / confusionMatrix.sum(axis=1)\n",
    "confusionMatrix[\"fpr\"] = confusionMatrix[0] / confusionMatrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b779ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'E:/Program Files (x86)/Graphviz2.38/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b4f94852",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m---> 79\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[38;5;241m*\u001b[39m, kwargs):\n\u001b[1;32m---> 99\u001b[0m     popen \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(cmd, stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    101\u001b[0m     stdin_write \u001b[38;5;241m=\u001b[39m popen\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39mwrite\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\subprocess.py:1440\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1440\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:972\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    969\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[1;34m(self, include, exclude, **_)\u001b[0m\n\u001b[0;32m     96\u001b[0m include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter_mimetype}\n\u001b[0;32m     97\u001b[0m include \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)()\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     96\u001b[0m include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter_mimetype}\n\u001b[0;32m     97\u001b[0m include \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_image_svg_xml\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msvg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSVG_ENCODING\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     56\u001b[0m          \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m          renderer: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m          engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     62\u001b[0m          encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m        '<?xml version='\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@_tools\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecate_positional_args(supported_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    114\u001b[0m                  \u001b[38;5;28mformat\u001b[39m: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m                  engine: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    120\u001b[0m                  encoding: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[1;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mlookup(encoding) \u001b[38;5;129;01mis\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding):\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;66;03m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_lines_string(\u001b[38;5;241m*\u001b[39margs, encoding\u001b[38;5;241m=\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m         raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_lines(\u001b[38;5;241m*\u001b[39margs, input_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\backend\\piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[1;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[0;32m    206\u001b[0m cmd \u001b[38;5;241m=\u001b[39m dot_command\u001b[38;5;241m.\u001b[39mcommand(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    207\u001b[0m                           renderer\u001b[38;5;241m=\u001b[39mrenderer,\n\u001b[0;32m    208\u001b[0m                           formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[0;32m    209\u001b[0m                           neato_no_op\u001b[38;5;241m=\u001b[39mneato_no_op)\n\u001b[0;32m    210\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_lines\u001b[39m\u001b[38;5;124m'\u001b[39m: input_lines, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding}\n\u001b[1;32m--> 212\u001b[0m proc \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mrun_check(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, quiet\u001b[38;5;241m=\u001b[39mquiet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\graphviz\\backend\\execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1434647d240>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = Pool(X_train, y_train, cat_features=categorical_features, feature_names=list(X_train.columns))\n",
    "model.plot_tree(\n",
    "    tree_idx=0,\n",
    "    pool=pool\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7388711",
   "metadata": {},
   "source": [
    "#### 2023-12-26补engagement,CR数据,加变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "b483cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taoye发了一波补充数据，原始的engagement这个数据被我已经加过了，如果前面数据处理部分全部重跑的话不需要再跑这个格子\n",
    "# 如果是从train_data 往后开始跑，还是要跑这个格子的； train_data是第一次建模处理好的数据\n",
    "engagement = pd.read_excel(\"data/engagement_data.xlsx\")  # ID 有重复\n",
    "engagement['ID'] = engagement['ID'].astype(str).str.split('.').apply(\n",
    "            lambda x: \"-\".join([str(list(x)[0]), str(list(x)[1])[:6]]))\n",
    "engagement = engagement.drop_duplicates(subset=['ID', 'year'], keep='first')\n",
    "\n",
    "engagement2 = engagement.set_index(['ID', 'year'])\n",
    "train_data2 = train_data.set_index(['ID', 'year'])\n",
    "train_data2['Employee Engagement Index'].update(engagement2['Employee Engagement Index'])\n",
    "train_data2['Manager Effectiveness Index'].update(engagement2['Manager Effectiveness Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "74225f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_suppliment = pd.read_excel(\"data/cr_补充数据_1226.xlsx\")\n",
    "cr_suppliment['ID'] = cr_suppliment['ID'].astype(str).str.split('.').apply(lambda x: \"-\".join([str(list(x)[0]), str(list(x)[1])[:6]]))\n",
    "cr_suppliment = cr_suppliment.set_index(['ID', 'year'])\n",
    "cr_suppliment['recent_cr'] = cr_suppliment['recent_cr'].replace({'外国人无权限': None})\n",
    "train_data2.update(cr_suppliment['recent_cr'])\n",
    "# 这两个forecast_fte补了跟没补是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "2e3f14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_src_copy = movement_src.copy()\n",
    "movement_src_copy = movement_src_copy[movement_src_copy['EmployeeStatus'] == 'Active']\n",
    "movement_src_copy['BAND'] = movement_src_copy['BAND'].replace(roam_to_num_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b685e5e",
   "metadata": {},
   "source": [
    "#### 12.27补engagement index 没有的话用line manager的line manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "acbb1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终的可以用于模型训练的数据final_train和预测数据final_forecast_fte\n",
    "final_train = get_days_in_position(train_data2.reset_index(), movement_src_copy)\n",
    "final_train = fill_in_engagement_index_blank(final_train, train_data)   # 补充engagement的数据\n",
    "final_train = add_combo_features(final_train)\n",
    "\n",
    "final_forecast_fte = get_days_in_position(forecast_fte.reset_index(), movement_src_copy)\n",
    "final_forecast_fte = fill_in_engagement_index_blank(final_forecast_fte, train_data)\n",
    "final_forecast_fte = add_combo_features(final_forecast_fte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "aa2214f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860, 43)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "a0841c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_excel(os.path.join(new_folder,'final_train.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0704a6",
   "metadata": {},
   "source": [
    "### 12.26更新建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "0f48ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modeling_train_dataset(train_data, save_train=False):\n",
    "#     train_data = train_data[(train_data['recent_cr'].notnull())]\n",
    "    print(\"Initial turnover records ratio: {:.2%}\".format(train_data['is_fte'].value_counts()[0] / train_data['is_fte'].value_counts().sum()))   \n",
    "    train_fte_trunc = train_data.query('is_fte == 1').sample(n=450, random_state=24)            # 让train data的离职人占比20% \n",
    "    train_data_sub = pd.concat([train_fte_trunc, train_data.query('is_fte == 0')])\n",
    "    train_data_sub = train_data_sub.reset_index(drop=True)\n",
    "    train_data_sub = train_data_sub[model_used_features]\n",
    "    train_data_sub['y'] = 1 - train_data_sub['is_fte']    # y是半年后是否离职，还有一种是y=duration\n",
    "    if save_train:\n",
    "        train_data_sub.to_excel(\"model_data/train.xlsx\")\n",
    "    for col in categorical_features:\n",
    "        train_data_sub[col] = train_data_sub[col].astype(str)\n",
    "        train_data_sub[col] = train_data_sub[col].fillna('NA')\n",
    "    return train_data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "689d6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used_features = pd.read_excel('模型标签.xlsx')['column'].tolist()\n",
    "categorical_features = ['Gender',  'end_of_date_position','end_of_date_MacroEntity','end_of_date_paid',\n",
    "                        'Organizational Unit','Line Manager ID', 'Job Family', '员工子组(OM)', '工作地 ID(OM)','Functional Area','opr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "fab2a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial turnover records ratio: 9.30%\n",
      "train turnover ratio: 14.62%\n",
      "test turnover ratio: 16.98%\n"
     ]
    }
   ],
   "source": [
    "train_data_sub = get_modeling_train_dataset(final_train, save_train=False)\n",
    "X = train_data_sub.drop(['ID', 'duration', 'is_fte', 'y'], axis=1)\n",
    "y = train_data_sub['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "print(\"train turnover ratio: {:.2%}\".format(y_train.value_counts()[1] / y_train.value_counts().sum()))\n",
    "print(\"test turnover ratio: {:.2%}\".format(y_test.value_counts()[1] / y_test.value_counts().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "ccf26e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96875"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(**params)\n",
    "model.fit(X_train, y_train,eval_set=[(X_train, y_train),(X_test,y_test)],cat_features=categorical_features)\n",
    "test_pred = [pred[1] for pred in  model.predict_proba(X_test)]\n",
    "test_auc= roc_auc_score(list(y_test), test_pred)\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "923dc94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.908153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   0       tpr       fpr\n",
       "1  18   0  1.000000  0.000000\n",
       "0   8  80  0.090909  0.908153"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.26\n",
    "confusion_mat = confusion_matrix(y_test.tolist(), [int(x > threshold) for x in test_pred])\n",
    "confusionMatrix = pd.DataFrame(confusion_mat, columns=[0, 1], index=[0, 1]). \\\n",
    "    sort_index(axis=0, ascending=False).sort_index(axis=1, ascending=False)\n",
    "confusionMatrix[\"tpr\"] = confusionMatrix[1] / confusionMatrix.sum(axis=1)\n",
    "confusionMatrix[\"fpr\"] = confusionMatrix[0] / confusionMatrix.sum(axis=1)\n",
    "confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "3dd26647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28079083\\AppData\\Local\\Temp\\ipykernel_19384\\3193478683.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast_data[col] = forecast_data[col].astype(str)\n",
      "C:\\Users\\28079083\\AppData\\Local\\Temp\\ipykernel_19384\\3193478683.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast_data[col] = forecast_data[col].fillna('NA')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1      4\n",
       "Name: turnover_tag, dtype: int64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_data = final_forecast_fte[X_train.columns]\n",
    "for col in categorical_features:\n",
    "    forecast_data[col] = forecast_data[col].astype(str)\n",
    "    forecast_data[col] = forecast_data[col].fillna('NA')\n",
    "    \n",
    "predict_proba = [pred[1] for pred in  model.predict_proba(forecast_data)]\n",
    "forecast_result = pd.concat([forecast_fte, pd.Series(predict_proba, name='predict_p', index=forecast_fte.index)], axis=1)\n",
    "forecast_result['turnover_tag'] = forecast_result['predict_p'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "forecast_result['turnover_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "15937012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model result\n",
    "new_folder = 'model_data/model_result1227'\n",
    "if not os.path.exists(new_folder):\n",
    "    os.mkdir(new_folder)\n",
    "result_save_file = pd.ExcelWriter(os.path.join(new_folder, \"model_result.xlsx\"))\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns, name=\"feature_importance\")\n",
    "feature_importance.sort_values(ascending=False)\n",
    "feature_importance.to_excel(result_save_file, sheet_name='feature_importance')\n",
    "\n",
    "confusionMatrix.to_excel(result_save_file, sheet_name='confusion_matrix')\n",
    "forecast_result.to_excel(result_save_file, sheet_name='forecast_result', index=False)\n",
    "train_data_sub.to_excel(result_save_file, sheet_name=\"train_and_test\", index=False)\n",
    "result_save_file.close()\n",
    "\n",
    "with open(os.path.join(new_folder, \"catboost_model.pk\"), \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(os.path.join(new_folder, \"catboost_model_params.txt\"), 'w') as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41900c85",
   "metadata": {},
   "source": [
    "### 分析变量影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "b5e597c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09302325581395349"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_src = final_train.copy()\n",
    "analysis_src['y'] = 1 - analysis_src['is_fte']\n",
    "analysis_src['y'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "1978b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_row = 0\n",
    "analyze_file = pd.ExcelWriter(os.path.join(new_folder,'analysis_data.xlsx'))\n",
    "analysis_src =train_data_sub.copy()\n",
    "analysis_src['cr_change_times'].fillna(0, inplace=True)\n",
    "a = analysis_src.groupby(['cr_change_times']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "b22ed16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in band 单变量\n",
    "analysis_src['time_in_band_grp'] = pd.cut(analysis_src['time_in_band'], [0, 0.5, 0.9, 1, 1.5, 2, 3, 4, 5])\n",
    "a = analysis_src.groupby(['time_in_band_grp']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['time_in_band_grp','cr_change_times']).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "3a8bb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_src['time_in_position_grp'] = pd.cut(analysis_src['time_in_position'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 15, 35])\n",
    "a = analysis_src.groupby(['time_in_position_grp']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['time_in_position_grp','cr_change_times']).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "f0b5b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_src['tenure'] = pd.cut(analysis_src['on_duty_days'] / 365, [0, 1, 2, 3, 4, 5, 6, 8, 10, 15, 35])\n",
    "a = analysis_src.groupby(['tenure'], dropna=False).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['tenure', 'cr_change_times']).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "analysis_src['promo_freq_vs_tenure_grp'] = pd.cut(analysis_src['promo_freq_vs_tenure'] * 365, [0, 0.1, 0.2, 0.3, 0.4, 1])\n",
    "a = analysis_src.groupby(['promo_freq_vs_tenure_grp'], dropna=False).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['promo_freq_vs_tenure_grp', 'tenure'], dropna=False).agg({'y': ['mean','count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "2a1d627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_src['cr_change_vs_term_grp'] = pd.cut(analysis_src['cr_change_vs_term'], [0, 0.25, 0.5, 0.75, 1, 1.5, 2, 500])\n",
    "a = analysis_src.groupby(['cr_change_vs_term_grp']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "5dd6f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_src['recent_cr_grp'] = pd.cut(analysis_src['recent_cr'], [0, 0.55, 0.6, 0.7, 0.8, 0.9, 1, 2])\n",
    "a = analysis_src.groupby(['recent_cr_grp']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_grp', 'time_in_band_grp']).agg({'y': ['mean','count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_grp', 'time_in_position_grp']).agg({'y': ['mean','count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_grp', 'tenure']).agg({'y': ['mean','count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "528237dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_src['recent_cr_diff_grp'] = pd.cut(analysis_src['recent_cr_diff'], [-0.4, -0.1, -0.05, 0, 0.05, 0.1, 0.25, 0.5])\n",
    "a = analysis_src.groupby(['recent_cr_diff_grp']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_diff_grp', 'time_in_band_grp']).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_diff_grp', 'time_in_position_grp']).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_diff_grp', 'tenure']).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "98f25cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# employee engagement index/ manager effectiveness index\n",
    "analysis_src['me_grp'] = pd.cut(analysis_src['Manager Effectiveness Index'], [10, 70, 80, 85, 90, 95, 98, 99, 100])\n",
    "analysis_src['me_grp'] = analysis_src['me_grp'].astype(str)\n",
    "a = analysis_src.groupby(['me_grp'], dropna=False).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "analysis_src['ee_grp'] = pd.cut(analysis_src['Employee Engagement Index'], [10, 60, 70, 80, 83, 85, 95, 97, 100])\n",
    "analysis_src['ee_grp'] = analysis_src['ee_grp'].astype(str)\n",
    "a = analysis_src.groupby(['ee_grp'], dropna=False).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "00ed0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_src['age_grp'] = pd.cut(analysis_src['Age'],[0, 25, 30, 35, 40, 45, 50, 56])\n",
    "a = analysis_src.groupby(['age_grp']).agg({'y': ['mean', 'count']}).reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['recent_cr_diff_grp', 'age_grp'], dropna=False).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['cr_change_vs_term_grp', 'age_grp'], dropna=False).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "2581a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = analysis_src.groupby(['recent_cr_grp', 'age_grp'], dropna=False).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['promo_freq_vs_tenure_grp', 'age_grp'], dropna=False).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "fc5be0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = analysis_src.groupby(['Organizational Unit']).agg({'y': ['mean', 'count']}).sort_values(by=('y',  'count'), ascending=False)\n",
    "a = a[a[('y', 'count')] >= 10].reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)\n",
    "current_row += len(a) + 4\n",
    "\n",
    "a = analysis_src.groupby(['end_of_date_position']).agg({'y': ['mean', 'count']}).sort_values(by=('y',  'count'), ascending=False)\n",
    "a.reset_index().to_excel(analyze_file, sheet_name='position')\n",
    "\n",
    "a = analysis_src.groupby(['time_in_band_grp', 'tenure'], dropna=False).agg({'y': ['mean', 'count']}).unstack().reset_index()\n",
    "a.to_excel(analyze_file, startrow=current_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "05716274",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861eef7",
   "metadata": {},
   "source": [
    "### 其他分析，离职率&缺失值等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "a44ff348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fte</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID\n",
       "is_fte     \n",
       "0        80\n",
       "1       180"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.groupby('is_fte').agg({'ID': pd.Series.nunique})   # 30%的离职率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "a3716ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fte\n",
       "0     80\n",
       "1    780\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.groupby('is_fte')['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "31d188c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                0\n",
       "Age                               0\n",
       "Gender                            0\n",
       "duration                          0\n",
       "is_fte                            0\n",
       "on_duty_days                      0\n",
       "move_up_times                     0\n",
       "days_since_recent_move_up       361\n",
       "move_down_times                   0\n",
       "days_since_recent_demotion      527\n",
       "other_move_times                  0\n",
       "days_since_recent_other_move    224\n",
       "end_of_date_band                  0\n",
       "end_of_date_position              0\n",
       "end_of_date_MacroEntity           0\n",
       "end_of_date_paid                  0\n",
       "year                              0\n",
       "Employee Engagement Index       127\n",
       "Manager Effectiveness Index     127\n",
       "recent_cr                        55\n",
       "days_since_recent_cr_change      71\n",
       "cr_change_times                  71\n",
       "recent_cr_diff                  165\n",
       "cr_change_vs_term                71\n",
       "Organizational Unit               0\n",
       "Line Manager ID                   0\n",
       "Job Family                        0\n",
       "员工子组(OM)                          0\n",
       "工作地 ID(OM)                        0\n",
       "Functional Area                   0\n",
       "time_in_position                  0\n",
       "opr                               0\n",
       "promo_days_vs_tenure            361\n",
       "promo_freq_vs_tenure              0\n",
       "time_in_band                    138\n",
       "cr_diff_vs_time_in_band         220\n",
       "y                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "6f4d07c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                0\n",
       "year                              0\n",
       "Age                               0\n",
       "Gender                            0\n",
       "PAID                              0\n",
       "MacroEntity                       0\n",
       "positionName                      0\n",
       "OnboardDate                       0\n",
       "duration                          0\n",
       "current_year                      0\n",
       "is_fte                            0\n",
       "current_band                      0\n",
       "on_duty_days                      0\n",
       "move_up_times                     0\n",
       "days_since_recent_move_up       593\n",
       "move_down_times                   0\n",
       "days_since_recent_demotion      855\n",
       "other_move_times                  0\n",
       "days_since_recent_other_move    368\n",
       "end_of_date_band                  0\n",
       "end_of_date_position              0\n",
       "end_of_date_MacroEntity           0\n",
       "end_of_date_paid                  0\n",
       "src_file                          0\n",
       "recent_cr                       100\n",
       "days_since_recent_cr_change     120\n",
       "cr_change_times                 120\n",
       "recent_cr_diff                  264\n",
       "cr_change_vs_term               120\n",
       "Organizational Unit             148\n",
       "Line Manager ID                 148\n",
       "Job Family                      162\n",
       "员工子组(OM)                        148\n",
       "工作地 ID(OM)                      148\n",
       "Functional Area                 162\n",
       "Employee Engagement Index       201\n",
       "Manager Effectiveness Index     201\n",
       "opr                             523\n",
       "promo_freq_vs_tenure              0\n",
       "promo_days_vs_tenure            593\n",
       "time_in_position                  0\n",
       "time_in_band                    230\n",
       "cr_diff_vs_time_in_band         357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dd026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
